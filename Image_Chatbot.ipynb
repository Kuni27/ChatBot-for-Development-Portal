{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## Distill Bert and MiniLM"
      ],
      "metadata": {
        "id": "XUbB_0zYTzay"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pip install pytesseract"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vm3ZdSfuRtu5",
        "outputId": "48740dae-1bab-4c63-d5eb-9bd79beeb950"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pytesseract\n",
            "  Downloading pytesseract-0.3.13-py3-none-any.whl.metadata (11 kB)\n",
            "Requirement already satisfied: packaging>=21.3 in /usr/local/lib/python3.11/dist-packages (from pytesseract) (24.2)\n",
            "Requirement already satisfied: Pillow>=8.0.0 in /usr/local/lib/python3.11/dist-packages (from pytesseract) (11.2.1)\n",
            "Downloading pytesseract-0.3.13-py3-none-any.whl (14 kB)\n",
            "Installing collected packages: pytesseract\n",
            "Successfully installed pytesseract-0.3.13\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9fd7876b",
        "outputId": "d56cd7bd-ef5a-48df-ae86-86185fcb5655"
      },
      "source": [
        "!pip install faiss-cpu"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: faiss-cpu in /usr/local/lib/python3.11/dist-packages (1.11.0)\n",
            "Requirement already satisfied: numpy<3.0,>=1.25.0 in /usr/local/lib/python3.11/dist-packages (from faiss-cpu) (2.0.2)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from faiss-cpu) (24.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install easyocr\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UIcSvSKnlrOM",
        "outputId": "df4161bd-018a-4f05-b576-09dcf51e52b1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: easyocr in /usr/local/lib/python3.11/dist-packages (1.7.2)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (from easyocr) (2.6.0+cu124)\n",
            "Requirement already satisfied: torchvision>=0.5 in /usr/local/lib/python3.11/dist-packages (from easyocr) (0.21.0+cu124)\n",
            "Requirement already satisfied: opencv-python-headless in /usr/local/lib/python3.11/dist-packages (from easyocr) (4.11.0.86)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from easyocr) (1.15.3)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from easyocr) (2.0.2)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.11/dist-packages (from easyocr) (11.2.1)\n",
            "Requirement already satisfied: scikit-image in /usr/local/lib/python3.11/dist-packages (from easyocr) (0.25.2)\n",
            "Requirement already satisfied: python-bidi in /usr/local/lib/python3.11/dist-packages (from easyocr) (0.6.6)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.11/dist-packages (from easyocr) (6.0.2)\n",
            "Requirement already satisfied: Shapely in /usr/local/lib/python3.11/dist-packages (from easyocr) (2.1.1)\n",
            "Requirement already satisfied: pyclipper in /usr/local/lib/python3.11/dist-packages (from easyocr) (1.3.0.post6)\n",
            "Requirement already satisfied: ninja in /usr/local/lib/python3.11/dist-packages (from easyocr) (1.11.1.4)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch->easyocr) (3.18.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch->easyocr) (4.14.0)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch->easyocr) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch->easyocr) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch->easyocr) (2025.3.2)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->easyocr) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->easyocr) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->easyocr) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch->easyocr) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch->easyocr) (12.4.5.8)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch->easyocr) (11.2.1.3)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch->easyocr) (10.3.5.147)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch->easyocr) (11.6.1.9)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch->easyocr) (12.3.1.170)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch->easyocr) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch->easyocr) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->easyocr) (12.4.127)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->easyocr) (12.4.127)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch->easyocr) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch->easyocr) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch->easyocr) (1.3.0)\n",
            "Requirement already satisfied: imageio!=2.35.0,>=2.33 in /usr/local/lib/python3.11/dist-packages (from scikit-image->easyocr) (2.37.0)\n",
            "Requirement already satisfied: tifffile>=2022.8.12 in /usr/local/lib/python3.11/dist-packages (from scikit-image->easyocr) (2025.6.11)\n",
            "Requirement already satisfied: packaging>=21 in /usr/local/lib/python3.11/dist-packages (from scikit-image->easyocr) (24.2)\n",
            "Requirement already satisfied: lazy-loader>=0.4 in /usr/local/lib/python3.11/dist-packages (from scikit-image->easyocr) (0.4)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch->easyocr) (3.0.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# swimlane_chatbot.py  (generic-image version)\n",
        "\n",
        "import gradio as gr\n",
        "import pytesseract\n",
        "import cv2\n",
        "import numpy as np\n",
        "from transformers import pipeline\n",
        "from sentence_transformers import SentenceTransformer\n",
        "import faiss\n",
        "import os, re\n",
        "\n",
        "# --------------------------------------------------\n",
        "# Models\n",
        "# --------------------------------------------------\n",
        "qa_pipeline = pipeline(\n",
        "    \"question-answering\",\n",
        "    model=\"distilbert-base-uncased-distilled-squad\",\n",
        "    handle_impossible_answer=True,\n",
        ")\n",
        "embedder = SentenceTransformer(\"all-MiniLM-L6-v2\")\n",
        "\n",
        "\n",
        "# --------------------------------------------------\n",
        "# OCR helper\n",
        "# --------------------------------------------------\n",
        "def _clean(txt: str) -> str:\n",
        "    txt = re.sub(r\"[\\n\\r]+\", \" \", txt)\n",
        "    txt = re.sub(r\"\\s{2,}\", \" \", txt)\n",
        "    return txt.strip(\" .-–\")\n",
        "\n",
        "\n",
        "def parse_diagram(image_np):\n",
        "    \"\"\"\n",
        "    Returns a list of step strings extracted from the diagram,\n",
        "    ordered roughly top-to-bottom then left-to-right.\n",
        "    \"\"\"\n",
        "    # 1) a little pre-processing so Tesseract can read light or dark backgrounds\n",
        "    gray = cv2.cvtColor(image_np, cv2.COLOR_BGR2GRAY)\n",
        "    gray = cv2.resize(gray, None, fx=1.6, fy=1.6, interpolation=cv2.INTER_CUBIC)\n",
        "    gray = cv2.adaptiveThreshold(\n",
        "        gray, 255, cv2.ADAPTIVE_THRESH_MEAN_C, cv2.THRESH_BINARY_INV, 31, 15\n",
        "    )\n",
        "\n",
        "    data = pytesseract.image_to_data(gray, output_type=pytesseract.Output.DICT, config=\"--psm 6\")\n",
        "    n = len(data[\"text\"])\n",
        "\n",
        "    # collect high-confidence words\n",
        "    boxes = []\n",
        "    for i in range(n):\n",
        "        if int(data[\"conf\"][i]) < 40:\n",
        "            continue\n",
        "        txt = _clean(data[\"text\"][i])\n",
        "        if len(txt) < 4:\n",
        "            continue\n",
        "        x, y = data[\"left\"][i], data[\"top\"][i]\n",
        "        boxes.append((y, x, txt))\n",
        "\n",
        "    if not boxes:\n",
        "        return []\n",
        "\n",
        "    # cluster by row (≈ swim lane) then sort left-to-right\n",
        "    ROW_H = 55\n",
        "    rows = {}\n",
        "    for y, x, t in boxes:\n",
        "        rows.setdefault(y // ROW_H, []).append((x, t))\n",
        "\n",
        "    ordered = []\n",
        "    for r in sorted(rows):\n",
        "        ordered.extend([t for x, t in sorted(rows[r])])\n",
        "\n",
        "    # de-duplicate while preserving order\n",
        "    seen = set()\n",
        "    steps = [s for s in ordered if not (s in seen or seen.add(s))]\n",
        "    return steps\n",
        "\n",
        "\n",
        "# --------------------------------------------------\n",
        "# QA per-image\n",
        "# --------------------------------------------------\n",
        "def answer_question(image, question: str):\n",
        "    steps = parse_diagram(image)\n",
        "    if not steps:\n",
        "        return \"I couldn’t read any steps; try a higher-resolution image.\"\n",
        "\n",
        "    # build FAISS on-the-fly\n",
        "    embeddings = embedder.encode(steps, convert_to_tensor=True).cpu().numpy()\n",
        "    index = faiss.IndexFlatL2(embeddings.shape[1])\n",
        "    index.add(embeddings)\n",
        "\n",
        "    q_emb = embedder.encode([question], convert_to_tensor=True).cpu().numpy()\n",
        "    D, I = index.search(q_emb, min(3, len(steps)))\n",
        "    context = \". \".join(steps[i] for i in I[0])\n",
        "\n",
        "    result = qa_pipeline(question=question, context=context)\n",
        "    if result.get(\"score\", 0) < 0.05 or not result[\"answer\"].strip():\n",
        "        return \"I’m not confident. Try rephrasing the question.\"\n",
        "    return result[\"answer\"].strip()\n",
        "\n",
        "\n",
        "# --------------------------------------------------\n",
        "# Gradio / CLI wrappers\n",
        "# --------------------------------------------------\n",
        "def chatbot_interface(image, question):\n",
        "    return answer_question(image, question)\n",
        "\n",
        "\n",
        "def cli_mode():\n",
        "    print(\"CLI mode – type 'exit' to quit\")\n",
        "    path = input(\"Diagram path: \").strip()\n",
        "    if not os.path.isfile(path):\n",
        "        print(\"File not found.\"); return\n",
        "    img = cv2.imread(path)\n",
        "    while True:\n",
        "        q = input(\"> \")\n",
        "        if q.lower() == \"exit\":\n",
        "            break\n",
        "        print(answer_question(img, q))\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    import sys\n",
        "    if len(sys.argv) > 1 and sys.argv[1] == \"cli\":\n",
        "        cli_mode()\n",
        "    else:\n",
        "        gr.Interface(\n",
        "            fn=chatbot_interface,\n",
        "            inputs=[\n",
        "                gr.Image(type=\"numpy\", label=\"Upload Swim-lane Diagram\"),\n",
        "                gr.Textbox(label=\"Question\", placeholder=\"Ask about the workflow…\"),\n",
        "            ],\n",
        "            outputs=gr.Textbox(label=\"Answer\"),\n",
        "            title=\"Swimlane Diagram Chatbot\",\n",
        "            description=\"Upload any swim-lane diagram, then ask questions about its steps.\",\n",
        "        ).launch()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 663
        },
        "id": "E_QmbNMQSrPQ",
        "outputId": "9e93f8ab-99a2-4ff8-c163-5fcd5ebb41da"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Device set to use cpu\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "It looks like you are running Gradio on a hosted Jupyter notebook, which requires `share=True`. Automatically setting `share=True` (you can turn this off by setting `share=False` in `launch()` explicitly).\n",
            "\n",
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "* Running on public URL: https://9eff65d1778bea9247.gradio.live\n",
            "\n",
            "This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://9eff65d1778bea9247.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install --upgrade gradio"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "3_ABhAhUlpeR",
        "outputId": "7f78f6f4-fd43-474e-90c0-df37954f45cc",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: gradio in /usr/local/lib/python3.11/dist-packages (5.31.0)\n",
            "Collecting gradio\n",
            "  Downloading gradio-5.34.2-py3-none-any.whl.metadata (16 kB)\n",
            "Requirement already satisfied: aiofiles<25.0,>=22.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (24.1.0)\n",
            "Requirement already satisfied: anyio<5.0,>=3.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (4.9.0)\n",
            "Requirement already satisfied: fastapi<1.0,>=0.115.2 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.115.12)\n",
            "Requirement already satisfied: ffmpy in /usr/local/lib/python3.11/dist-packages (from gradio) (0.6.0)\n",
            "Collecting gradio-client==1.10.3 (from gradio)\n",
            "  Downloading gradio_client-1.10.3-py3-none-any.whl.metadata (7.1 kB)\n",
            "Requirement already satisfied: groovy~=0.1 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.1.2)\n",
            "Requirement already satisfied: httpx>=0.24.1 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.28.1)\n",
            "Requirement already satisfied: huggingface-hub>=0.28.1 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.33.0)\n",
            "Requirement already satisfied: jinja2<4.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (3.1.6)\n",
            "Requirement already satisfied: markupsafe<4.0,>=2.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (3.0.2)\n",
            "Requirement already satisfied: numpy<3.0,>=1.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (2.0.2)\n",
            "Requirement already satisfied: orjson~=3.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (3.10.18)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from gradio) (24.2)\n",
            "Requirement already satisfied: pandas<3.0,>=1.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (2.2.2)\n",
            "Requirement already satisfied: pillow<12.0,>=8.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (11.2.1)\n",
            "Requirement already satisfied: pydantic<2.12,>=2.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (2.11.7)\n",
            "Requirement already satisfied: pydub in /usr/local/lib/python3.11/dist-packages (from gradio) (0.25.1)\n",
            "Requirement already satisfied: python-multipart>=0.0.18 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.0.20)\n",
            "Requirement already satisfied: pyyaml<7.0,>=5.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (6.0.2)\n",
            "Requirement already satisfied: ruff>=0.9.3 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.11.13)\n",
            "Requirement already satisfied: safehttpx<0.2.0,>=0.1.6 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.1.6)\n",
            "Requirement already satisfied: semantic-version~=2.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (2.10.0)\n",
            "Requirement already satisfied: starlette<1.0,>=0.40.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.46.2)\n",
            "Requirement already satisfied: tomlkit<0.14.0,>=0.12.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.13.3)\n",
            "Requirement already satisfied: typer<1.0,>=0.12 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.16.0)\n",
            "Requirement already satisfied: typing-extensions~=4.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (4.14.0)\n",
            "Requirement already satisfied: uvicorn>=0.14.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.34.3)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from gradio-client==1.10.3->gradio) (2025.3.2)\n",
            "Requirement already satisfied: websockets<16.0,>=10.0 in /usr/local/lib/python3.11/dist-packages (from gradio-client==1.10.3->gradio) (15.0.1)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.11/dist-packages (from anyio<5.0,>=3.0->gradio) (3.10)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio<5.0,>=3.0->gradio) (1.3.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx>=0.24.1->gradio) (2025.6.15)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx>=0.24.1->gradio) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx>=0.24.1->gradio) (0.16.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.28.1->gradio) (3.18.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.28.1->gradio) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.28.1->gradio) (4.67.1)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.28.1->gradio) (1.1.3)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas<3.0,>=1.0->gradio) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas<3.0,>=1.0->gradio) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas<3.0,>=1.0->gradio) (2025.2)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<2.12,>=2.0->gradio) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<2.12,>=2.0->gradio) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<2.12,>=2.0->gradio) (0.4.1)\n",
            "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0,>=0.12->gradio) (8.2.1)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0,>=0.12->gradio) (1.5.4)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0,>=0.12->gradio) (13.9.4)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas<3.0,>=1.0->gradio) (1.17.0)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (2.19.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.28.1->gradio) (3.4.2)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.28.1->gradio) (2.4.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0,>=0.12->gradio) (0.1.2)\n",
            "Downloading gradio-5.34.2-py3-none-any.whl (54.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m54.3/54.3 MB\u001b[0m \u001b[31m9.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading gradio_client-1.10.3-py3-none-any.whl (323 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m323.6/323.6 kB\u001b[0m \u001b[31m23.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: gradio-client, gradio\n",
            "  Attempting uninstall: gradio-client\n",
            "    Found existing installation: gradio_client 1.10.1\n",
            "    Uninstalling gradio_client-1.10.1:\n",
            "      Successfully uninstalled gradio_client-1.10.1\n",
            "  Attempting uninstall: gradio\n",
            "    Found existing installation: gradio 5.31.0\n",
            "    Uninstalling gradio-5.31.0:\n",
            "      Successfully uninstalled gradio-5.31.0\n",
            "Successfully installed gradio-5.34.2 gradio-client-1.10.3\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "gradio"
                ]
              },
              "id": "1fce2ab475fb449b96d3a6e0271b0697"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Roberta Base Squad"
      ],
      "metadata": {
        "id": "cBrL_0RiUEbF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import os\n",
        "import re\n",
        "from collections import defaultdict\n",
        "from typing import List, Dict, Tuple\n",
        "\n",
        "import cv2\n",
        "import numpy as np\n",
        "import faiss\n",
        "import gradio as gr\n",
        "import easyocr\n",
        "from sentence_transformers import SentenceTransformer\n",
        "from transformers import pipeline\n",
        "\n",
        "\n",
        "auto_gpu = False  # set True if you have a CUDA GPU and EasyOCR was compiled w/ GPU\n",
        "ocr_reader = easyocr.Reader([\"en\"], gpu=auto_gpu)\n",
        "qa_model = pipeline(\"question-answering\", model=\"deepset/roberta-base-squad2\")\n",
        "embedder = SentenceTransformer(\"all-mpnet-base-v2\")\n",
        "\n",
        "\n",
        "doc_chunks = [\n",
        "    \"To place an order, the customer submits a request via the UI.\",\n",
        "    \"The Sales team confirms receipt and checks if the product is in stock.\",\n",
        "    \"If not in stock, the order is canceled.\",\n",
        "    \"If in stock, the system checks credit card validity before processing payment.\",\n",
        "    \"Finance handles payment and initiates order delivery.\",\n",
        "]\n",
        "\n",
        "doc_emb = embedder.encode(doc_chunks, convert_to_numpy=True)\n",
        "faiss_index = faiss.IndexFlatL2(doc_emb.shape[1])\n",
        "faiss_index.add(doc_emb)\n",
        "\n",
        "\n",
        "STEP_ALIASES = {\n",
        "    # ordering/step aliases\n",
        "    \"submit order\": \"place order\",\n",
        "    \"order submitted\": \"place order\",\n",
        "    \"order is submitted\": \"place order\",\n",
        "    \"buy now\": \"place order\",\n",
        "    \"order placed\": \"place order\",\n",
        "    \"checkout\": \"place order\",\n",
        "\n",
        "    \"verify inventory\": \"check inventory\",\n",
        "    \"stock check\": \"check inventory\",\n",
        "    \"inventory check\": \"check inventory\",\n",
        "\n",
        "    \"charge card\": \"processing the payment\",\n",
        "    \"make payment\": \"processing the payment\",\n",
        "    \"payment\": \"processing the payment\",\n",
        "\n",
        "    \"delivery\": \"deliver the order\",\n",
        "    \"shipment\": \"deliver the order\",\n",
        "    \"dispatch\": \"deliver the order\",\n",
        "\n",
        "    \"refund\": \"cancel the order\",\n",
        "}\n",
        "\n",
        "FIRST_REGEX = re.compile(r\"first step|start|begin\", re.I)\n",
        "LAST_REGEX = re.compile(r\"last step|final|finish|end\", re.I)\n",
        "AFTER_REGEX = re.compile(r\"after (?:the )?(.*)\", re.I)\n",
        "BEFORE_REGEX = re.compile(r\"before (?:the )?(.*)\", re.I)\n",
        "WHO_REGEX = re.compile(r\"who|which team|which lane|responsible\", re.I)\n",
        "\n",
        "\n",
        "def _norm(txt: str) -> str:\n",
        "    txt = txt.lower().strip()\n",
        "    txt = re.sub(r\"[^a-z0-9 ]\", \"\", txt)\n",
        "    return STEP_ALIASES.get(txt, txt)\n",
        "\n",
        "\n",
        "def _cluster_rows(coords: List[int], eps: int = 40) -> Dict[int, List[int]]:\n",
        "    \"\"\"Group y‑coordinates using a simple 1‑D DBSCAN‑like clustering.\"\"\"\n",
        "    if not coords:\n",
        "        return {}\n",
        "    coords = sorted(coords)\n",
        "    clusters, current = defaultdict(list), 0\n",
        "    clusters[current].append(coords[0])\n",
        "    for y in coords[1:]:\n",
        "        if abs(y - clusters[current][-1]) <= eps:\n",
        "            clusters[current].append(y)\n",
        "        else:\n",
        "            current += 1\n",
        "            clusters[current].append(y)\n",
        "    return clusters\n",
        "\n",
        "\n",
        "def parse_diagram(image: np.ndarray) -> Tuple[List[str], str]:\n",
        "    # OCR\n",
        "    detected = ocr_reader.readtext(image)\n",
        "\n",
        "    # Collect (row, col, text)\n",
        "    raw_nodes: List[Tuple[int, int, str]] = []\n",
        "    y_coords: List[int] = []\n",
        "    for (bbox, text, conf) in detected:\n",
        "        text = text.strip()\n",
        "        if len(text) < 2:\n",
        "            continue\n",
        "        x, y = int(bbox[0][0]), int(bbox[0][1])\n",
        "        raw_nodes.append((y, x, text))\n",
        "        y_coords.append(y)\n",
        "\n",
        "    row_clusters = _cluster_rows(y_coords)\n",
        "\n",
        "    row_id_of_y = {}\n",
        "    for cid, ys in row_clusters.items():\n",
        "        for y in ys:\n",
        "            row_id_of_y[y] = cid\n",
        "\n",
        "    rows: Dict[int, List[Tuple[int, str]]] = defaultdict(list)\n",
        "    for y, x, text in raw_nodes:\n",
        "        cid = row_id_of_y[y]\n",
        "        rows[cid].append((x, text))\n",
        "\n",
        "    ordered_steps: List[str] = []\n",
        "    for cid in sorted(rows.keys()):\n",
        "        for x, text in sorted(rows[cid]):\n",
        "            ordered_steps.append(_norm(text))\n",
        "\n",
        "\n",
        "    seen = set()\n",
        "    dedup_steps = []\n",
        "    for s in ordered_steps:\n",
        "        if s in seen or len(s) < 2:\n",
        "            continue\n",
        "        seen.add(s)\n",
        "        dedup_steps.append(s)\n",
        "\n",
        "    pretty = \"\\n\".join(f\"Step {i+1}: {step.title()}\" for i, step in enumerate(dedup_steps))\n",
        "    return dedup_steps, pretty\n",
        "\n",
        "\n",
        "def _flow_reasoning(steps: List[str], question: str) -> str:\n",
        "    q_norm = question.lower()\n",
        "    # First / Last\n",
        "    if FIRST_REGEX.search(q_norm):\n",
        "        return steps[0]\n",
        "    if LAST_REGEX.search(q_norm):\n",
        "        return steps[-1]\n",
        "\n",
        "    # After X / Before X\n",
        "    m_after = AFTER_REGEX.search(q_norm)\n",
        "    if m_after:\n",
        "        ref = _norm(m_after.group(1))\n",
        "        if ref in steps and steps.index(ref) < len(steps) - 1:\n",
        "            return steps[steps.index(ref) + 1]\n",
        "    m_before = BEFORE_REGEX.search(q_norm)\n",
        "    if m_before:\n",
        "        ref = _norm(m_before.group(1))\n",
        "        if ref in steps and steps.index(ref) > 0:\n",
        "            return steps[steps.index(ref) - 1]\n",
        "    return \"\"\n",
        "\n",
        "\n",
        "def answer_question(image: np.ndarray, question: str) -> str:\n",
        "    steps, flow_text = parse_diagram(image)\n",
        "\n",
        "    rule_ans = _flow_reasoning(steps, question)\n",
        "    if rule_ans:\n",
        "        return rule_ans.capitalize()\n",
        "\n",
        "    # Build temp FAISS index with flow text\n",
        "    flow_emb = embedder.encode([flow_text], convert_to_numpy=True)\n",
        "    temp_index = faiss.IndexFlatL2(flow_emb.shape[1])\n",
        "    temp_index.add(np.vstack([doc_emb, flow_emb]))\n",
        "\n",
        "    # retrieval\n",
        "    q_emb = embedder.encode([question], convert_to_numpy=True)\n",
        "    D, I = temp_index.search(q_emb, 4)\n",
        "    context = \"\\n\".join((doc_chunks + [flow_text])[i] for i in I[0])\n",
        "\n",
        "    # LLM QA\n",
        "    try:\n",
        "        res = qa_model(question=question, context=context)\n",
        "        if res.get(\"answer\"):\n",
        "            return res[\"answer\"].capitalize()\n",
        "    except Exception:\n",
        "        pass\n",
        "    return \"Sorry, I couldn't find that in the current workflow.\"\n",
        "\n",
        "\n",
        "def chatbot_interface(image, question):\n",
        "    if image is None or question.strip() == \"\":\n",
        "        return \"Please provide both a diagram image and a question.\"\n",
        "    return answer_question(image, question)\n",
        "\n",
        "\n",
        "def cli_mode():\n",
        "    print(\"CLI Chatbot Mode  |  type 'exit' to quit\")\n",
        "    img_path = input(\"Image path: \")\n",
        "    if not os.path.exists(img_path):\n",
        "        print(\"Image file not found.\")\n",
        "        return\n",
        "    img = cv2.imread(img_path)\n",
        "\n",
        "    while True:\n",
        "        q = input(\"Q: \")\n",
        "        if q.lower() == \"exit\":\n",
        "            break\n",
        "        print(\"A:\", chatbot_interface(img, q))\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    import sys\n",
        "\n",
        "    if len(sys.argv) > 1 and sys.argv[1] == \"cli\":\n",
        "        cli_mode()\n",
        "    else:\n",
        "        gr.Interface(\n",
        "            fn=chatbot_interface,\n",
        "            inputs=[gr.Image(type=\"numpy\", label=\"Swim‑lane diagram\"),\n",
        "                    gr.Textbox(placeholder=\"Ask a question about the workflow…\", label=\"Question\")],\n",
        "            outputs=gr.Textbox(label=\"Answer\"),\n",
        "            title=\"Swim‑lane Diagram Chatbot (Robust)\",\n",
        "            description=\"Upload a process swim‑lane diagram then ask questions like 'What happens after the order is submitted?' or 'Who handles payment?'\"\n",
        "        ).launch(debug = True)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 695
        },
        "id": "7KyT1onCqW99",
        "outputId": "8d0531b6-4749-4dc6-f81f-88761697022b"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:easyocr.easyocr:Using CPU. Note: This module is much faster with a GPU.\n",
            "Device set to use cpu\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "It looks like you are running Gradio on a hosted Jupyter notebook, which requires `share=True`. Automatically setting `share=True` (you can turn this off by setting `share=False` in `launch()` explicitly).\n",
            "\n",
            "Colab notebook detected. This cell will run indefinitely so that you can see errors and logs. To turn off, set debug=False in launch().\n",
            "* Running on public URL: https://6bcbc71262246f275b.gradio.live\n",
            "\n",
            "This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://6bcbc71262246f275b.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Keyboard interruption in main thread... closing server.\n",
            "Killing tunnel 127.0.0.1:7876 <> https://6bcbc71262246f275b.gradio.live\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Km2vpnmRq_5W"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}